{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note for creation of RL environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/fabienfrfr/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/fabienfrfr/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/fabienfrfr/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "import random, numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('words')\n",
    "#nltk.download()\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "# https://github.com/RaRe-Technologies/gensim-data\n",
    "#path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "path = api.load('glove-wiki-gigaword-100', return_path=True) ## use this ! --> general knowledge\n",
    "#path = api.load(\"glove-twitter-25\", return_path=True) ## not use this !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question de math simple aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplifiez l'expression : 0\n",
      "La simplification de l'expression est : 0\n",
      "\n",
      "Résolvez l'équation : Eq(x**2 - 4, 0)\n",
      "Les solutions de l'équation sont : [-2, 2]\n",
      "\n",
      "Calculez la dérivée de cos(x)\n",
      "La dérivée de cos(x) est : cos(x)\n",
      "\n",
      "Calculez l'intégrale de x**3/3\n",
      "L'intégrale de x**3/3 est : x**3/3\n",
      "\n",
      "Calculez la distance entre les points APoint2D(0, 0) et BPoint2D(3, 4)\n",
      "La distance entre les points A et B est : 5\n",
      "\n",
      "Calculez le produit matriciel AB\n",
      "Le produit matriciel AB est : Matrix([[19, 22], [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "from sympy.stats import P, E, variance, Die, Normal\n",
    "\n",
    "# Simplification\n",
    "x = Symbol('x')\n",
    "expr = simplify((x + 1)**2 - x**2 - 2*x - 1)\n",
    "question_simplification = f\"Simplifiez l'expression : {expr}\"\n",
    "solution_simplification = f\"La simplification de l'expression est : {simplify(expr)}\"\n",
    "\n",
    "# Résolution d'équations\n",
    "eq = Eq(x**2 - 4, 0)\n",
    "question_resolution = f\"Résolvez l'équation : {eq}\"\n",
    "solution_resolution = f\"Les solutions de l'équation sont : {solve(eq)}\"\n",
    "\n",
    "# Calcul différentiel\n",
    "expr_diff = diff(sin(x), x)\n",
    "question_differentiel = f\"Calculez la dérivée de {expr_diff}\"\n",
    "solution_differentiel = f\"La dérivée de {expr_diff} est : {expr_diff}\"\n",
    "\n",
    "# Calcul intégral\n",
    "expr_integrale = integrate(x**2, x)\n",
    "question_integrale = f\"Calculez l'intégrale de {expr_integrale}\"\n",
    "solution_integrale = f\"L'intégrale de {expr_integrale} est : {expr_integrale}\"\n",
    "\n",
    "\"\"\"\n",
    "# Probabilités\n",
    "p = Symbol('p', positive=True)\n",
    "rv = bernoulli('X', p)\n",
    "question_proba = f\"Calculez la probabilité de {rv} = 1\"\n",
    "solution_proba = f\"La probabilité de {rv} = 1 est : {P(Eq(rv, 1))}\"\n",
    "\"\"\"\n",
    "# Géométrie\n",
    "point_A = Point(0, 0)\n",
    "point_B = Point(3, 4)\n",
    "distance_AB = point_A.distance(point_B)\n",
    "question_geometrie = f\"Calculez la distance entre les points A{point_A} et B{point_B}\"\n",
    "solution_geometrie = f\"La distance entre les points A et B est : {distance_AB}\"\n",
    "\"\"\"\n",
    "# Calcul symbolique - Laplace\n",
    "t = symbols('t', positive=True)\n",
    "f = Function('f')(t)\n",
    "laplace_transform = laplace_transform(f, t, s)\n",
    "question_laplace = f\"Calculez la transformation de Laplace de {f}\"\n",
    "solution_laplace = f\"La transformation de Laplace de {f} est : {laplace_transform}\"\n",
    "\"\"\"\n",
    "\n",
    "# Algèbre linéaire\n",
    "A = Matrix([[1, 2], [3, 4]])\n",
    "B = Matrix([[5, 6], [7, 8]])\n",
    "produit_matriciel = A * B\n",
    "question_algebre = f\"Calculez le produit matriciel AB\"\n",
    "solution_algebre = f\"Le produit matriciel AB est : {produit_matriciel}\"\n",
    "\n",
    "# Affichage des questions et des solutions\n",
    "print(question_simplification)\n",
    "print(solution_simplification)\n",
    "print()\n",
    "print(question_resolution)\n",
    "print(solution_resolution)\n",
    "print()\n",
    "print(question_differentiel)\n",
    "print(solution_differentiel)\n",
    "print()\n",
    "print(question_integrale)\n",
    "print(solution_integrale)\n",
    "print()\n",
    "\"\"\"\n",
    "print(question_proba)\n",
    "print(solution_proba)\n",
    "print()\n",
    "\"\"\"\n",
    "print(question_geometrie)\n",
    "print(solution_geometrie)\n",
    "print()\n",
    "\"\"\"\n",
    "print(question_laplace)\n",
    "print(solution_laplace)\n",
    "print()\n",
    "\"\"\"\n",
    "print(question_algebre)\n",
    "print(solution_algebre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Dériver l'expression : x**2\n",
      "Réponse: 2*x\n"
     ]
    }
   ],
   "source": [
    "def generer_question_mathematique():\n",
    "    x, y = symbols('x y')\n",
    "\n",
    "    # Choix aléatoire de l'opération\n",
    "    operations = [\n",
    "        ('Simplifier', lambda: (f\"Simplifier l'expression : {(x + y) ** 2}\", simplify((x + y) ** 2))),\n",
    "        ('Résoudre', lambda: (f\"Résoudre l'équation : {Eq(x ** 2 - 4, 0)}\", solve(Eq(x ** 2 - 4, 0), x))),\n",
    "        ('Dérivée', lambda: (f\"Dériver l'expression : {x ** 2}\", diff(x ** 2, x))),\n",
    "        ('Intégrale', lambda: (f\"Intégrer l'expression : {x ** 2}\", integrate(x ** 2, x)))\n",
    "    ]\n",
    "\n",
    "    operation, operation_function = random.choice(operations)\n",
    "\n",
    "    question, reponse = operation_function()\n",
    "\n",
    "    return question, reponse\n",
    "\n",
    "# Exemple d'utilisation\n",
    "question, reponse = generer_question_mathematique()\n",
    "print(\"Question:\", question)\n",
    "print(\"Réponse:\", reponse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarité sémantique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7682328820228577),\n",
       " ('queen', 0.7507690787315369),\n",
       " ('son', 0.7020888328552246),\n",
       " ('brother', 0.6985775232315063),\n",
       " ('monarch', 0.6977890729904175),\n",
       " ('throne', 0.6919989585876465),\n",
       " ('kingdom', 0.6811409592628479),\n",
       " ('father', 0.6802029013633728),\n",
       " ('emperor', 0.6712858080863953),\n",
       " ('ii', 0.6676074266433716)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in-process', 0.5989794135093689),\n",
       " ('recreative', 0.5940597057342529),\n",
       " ('asie', 0.5808883905410767),\n",
       " ('biohazards', 0.5794574618339539),\n",
       " ('nizhal', 0.5763342380523682),\n",
       " ('nanophotonics', 0.5746825933456421),\n",
       " ('cheminformatics', 0.565703272819519),\n",
       " ('neuters', 0.5651610493659973),\n",
       " ('s.s.d.', 0.5649306178092957),\n",
       " ('higher-grade', 0.5601018667221069)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative=['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6865564584732056)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['king', 'lady'], negative=['boy'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cool', 0.771088719367981),\n",
       " ('cold', 0.7251606583595276),\n",
       " ('warm', 0.6978106498718262),\n",
       " ('heat', 0.6798572540283203),\n",
       " ('soft', 0.6601648926734924),\n",
       " ('dry', 0.656905472278595),\n",
       " ('hottest', 0.6359643936157227),\n",
       " ('ice', 0.6257197260856628),\n",
       " ('mix', 0.6253519058227539),\n",
       " ('summer', 0.618662416934967)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vajiravudh', 0.5658568143844604)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['king'], negative=['bad'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('concepts', 0.8033155202865601),\n",
       " ('idea', 0.7895005941390991),\n",
       " ('notion', 0.785396158695221),\n",
       " ('theory', 0.7499698996543884),\n",
       " ('approach', 0.7274999618530273),\n",
       " ('model', 0.7105569839477539),\n",
       " ('unique', 0.7098757028579712),\n",
       " ('design', 0.7056307792663574),\n",
       " ('context', 0.700995683670044),\n",
       " ('ideas', 0.6954828500747681)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"concept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cihat', 0.5671901106834412),\n",
       " ('tamie', 0.5475354194641113),\n",
       " ('cuttaree', 0.5468041896820068),\n",
       " ('djeneral', 0.545489490032196),\n",
       " ('nanka', 0.5440961122512817),\n",
       " ('berdiyev', 0.5363784432411194),\n",
       " ('2-80', 0.5283413529396057),\n",
       " ('nasima', 0.5243364572525024),\n",
       " ('kurshid', 0.5243039727210999),\n",
       " ('fofanah', 0.5219519734382629)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative=['design'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = [\" concept of \", \" idea of \", \" notion of \", \" model of \", \" context of \", \" design of \"]\n",
    "relation_list = [' has similitude to', ' is close to', ' is near to', ' is resembling to', ' is approaching to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generer ce type de phrase\n",
    "#thing and stuff (are part of / belong to) the same concept/context/idea/category/class\n",
    "#thing is close/near to context/concept/idea of stuff\n",
    "#thing have simililarity to stuff\n",
    "\n",
    "\n",
    "# thing peut etre faux\n",
    "# mais aussi les relations ! par exemple : thing have patatoes to stuff --> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398053"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mots = [i for i in list(model.key_to_index.keys()) if len(i)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutchison is near to idea of unicom\n",
      "98.38 is approaching to idea of 98.43\n",
      "sumon is near to concept of cubilla\n",
      "dabhade is resembling to concept of matsunami\n",
      "ritziest is near to design of toniest\n",
      "blaque is similar to idea of eisbrecher\n",
      "mego is close to concept of tri-ang\n",
      "1.885 is close to concept of 1.785\n",
      "deledda is approaching to concept of duflot\n",
      "dailykos is near to design of freerepublic.com\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    mot = np.random.choice(mots)\n",
    "    sim = model.most_similar(mot, topn=3)\n",
    "    sim_mot = np.random.choice([s[0] for s in sim])\n",
    "    print(mot + np.random.choice(relation_list) + np.random.choice(context_list) + sim_mot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code est long, mais pas mal, par contre, la phrase doit etre plus \"mathématique\".\n",
    "Par exemple : \"dailykos is near to design of freerepublic.com\" est faux, c'est limite des opposées politiques...\n",
    "Trouver un moyen de simplifier ? juste concept ? meme catégorie ? point commun ?\n",
    "\n",
    "maintenant, la notion d'inclusion par les hypernymes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonymes: ['dog', 'domestic_dog', 'Canis_familiaris', 'frump', 'dog', 'dog', 'cad', 'bounder', 'blackguard', 'dog', 'hound', 'heel', 'frank', 'frankfurter', 'hotdog', 'hot_dog', 'dog', 'wiener', 'wienerwurst', 'weenie', 'pawl', 'detent', 'click', 'dog', 'andiron', 'firedog', 'dog', 'dog-iron', 'chase', 'chase_after', 'trail', 'tail', 'tag', 'give_chase', 'dog', 'go_after', 'track']\n",
      "Antonymes: []\n",
      "Hyponymes: ['basenji', 'corgi', 'Welsh_corgi', 'cur', 'mongrel', 'mutt', 'dalmatian', 'coach_dog', 'carriage_dog', 'Great_Pyrenees', 'griffon', 'Brussels_griffon', 'Belgian_griffon', 'hunting_dog', 'lapdog', 'Leonberg', 'Mexican_hairless', 'Newfoundland', 'Newfoundland_dog', 'pooch', 'doggie', 'doggy', 'barker', 'bow-wow', 'poodle', 'poodle_dog', 'pug', 'pug-dog', 'puppy', 'spitz', 'toy_dog', 'toy', 'working_dog', 'perisher', 'Vienna_sausage', 'hound', 'hunt', 'trace', 'quest', 'run_down', 'tree']\n",
      "Hyperonymes: ['canine', 'canid', 'domestic_animal', 'domesticated_animal', 'unpleasant_woman', 'disagreeable_woman', 'chap', 'fellow', 'feller', 'fella', 'lad', 'gent', 'blighter', 'cuss', 'bloke', 'villain', 'scoundrel', 'sausage', 'catch', 'stop', 'support', 'pursue', 'follow']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def trouver_synonymes(mot):\n",
    "    synonymes = []\n",
    "    for syn in wordnet.synsets(mot):\n",
    "        for lem in syn.lemmas():\n",
    "            synonymes.append(lem.name())\n",
    "    return synonymes\n",
    "\n",
    "def trouver_antonymes(mot):\n",
    "    antonymes = []\n",
    "    for syn in wordnet.synsets(mot):\n",
    "        for lem in syn.lemmas():\n",
    "            for antonym in lem.antonyms():\n",
    "                antonymes.append(antonym.name())\n",
    "    return antonymes\n",
    "\n",
    "def trouver_hyponymes(mot):\n",
    "    hyponymes = []\n",
    "    for syn in wordnet.synsets(mot):\n",
    "        for hyponym in syn.hyponyms():\n",
    "            for lem in hyponym.lemmas():\n",
    "                hyponymes.append(lem.name())\n",
    "    return hyponymes\n",
    "\n",
    "def trouver_hyperonymes(mot):\n",
    "    hyperonymes = []\n",
    "    for syn in wordnet.synsets(mot):\n",
    "        for hypernym in syn.hypernyms():\n",
    "            for lem in hypernym.lemmas():\n",
    "                hyperonymes.append(lem.name())\n",
    "    return hyperonymes\n",
    "\n",
    "# Exemple d'utilisation\n",
    "mot = \"dog\"\n",
    "\n",
    "synonymes = trouver_synonymes(mot)\n",
    "antonymes = trouver_antonymes(mot)\n",
    "hyponymes = trouver_hyponymes(mot)\n",
    "hyperonymes = trouver_hyperonymes(mot)\n",
    "\n",
    "print(\"Synonymes:\", synonymes)\n",
    "print(\"Antonymes:\", antonymes)\n",
    "print(\"Hyponymes:\", hyponymes)\n",
    "print(\"Hyperonymes:\", hyperonymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clericalist is include to disciple\n",
      "siding is include to railroad_track\n"
     ]
    }
   ],
   "source": [
    "mots = nltk.corpus.words.words()\n",
    "\n",
    "def hyperonym(mot):\n",
    "    hyperonyms = []\n",
    "    for syn in wordnet.synsets(mot):\n",
    "        for hypernym in syn.hypernyms():\n",
    "            for lem in hypernym.lemmas():\n",
    "                hyperonyms.append(lem.name())\n",
    "    return hyperonyms\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10) :\n",
    "    mot_aleatoire = random.choice(mots)\n",
    "    hypermot = hyperonym(mot_aleatoire)\n",
    "    if type(hypermot) == list and len(hypermot) > 0 :\n",
    "        hypermot = hypermot[0]\n",
    "        print(mot_aleatoire + \" is include to \" + hypermot)\n",
    "    elif type(hypermot) == str :\n",
    "        print(mot_aleatoire + \" is include to \" + hypermot)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('including', 0.891806960105896),\n",
       "  ('included', 0.8828111290931702),\n",
       "  ('such', 0.8553616404533386),\n",
       "  ('addition', 0.8527200818061829),\n",
       "  ('includes', 0.8213803768157959),\n",
       "  ('various', 0.7874671220779419),\n",
       "  ('other', 0.764614462852478),\n",
       "  ('notably', 0.7489321827888489),\n",
       "  ('example', 0.743007481098175),\n",
       "  ('variety', 0.7421876192092896)],\n",
       " [('containing', 0.8209840059280396),\n",
       "  ('contained', 0.800214409828186),\n",
       "  ('contains', 0.746664822101593),\n",
       "  ('produce', 0.6741648316383362),\n",
       "  ('material', 0.6602709889411926),\n",
       "  ('these', 0.6542306542396545),\n",
       "  ('contents', 0.6378759741783142),\n",
       "  ('certain', 0.6250300407409668),\n",
       "  ('amounts', 0.6236220598220825),\n",
       "  ('create', 0.6177904605865479)])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"include\"), model.most_similar(\"contain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a is an element of A, member of, include to, example of\n",
    "# A contains a, includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore Brunnichia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/fabien/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "def generer_phrase_subjective():\n",
    "    sujets = [\"J'aime\", \"Je déteste\", \"J'adore\", \"Je préfère\", \"Je trouve\", \"Je pense\", \"Je suis fan de\", \"Je suis passionné par\"]\n",
    "    mots = nltk.corpus.words.words()\n",
    "    \n",
    "    mot_aleatoire = random.choice(mots)\n",
    "    sujet_aleatoire = random.choice(sujets)\n",
    "    \n",
    "    phrase = \"{} {}\".format(sujet_aleatoire, mot_aleatoire)\n",
    "    return phrase\n",
    "\n",
    "# Exemple d'utilisation\n",
    "phrase_subjective = generer_phrase_subjective()\n",
    "print(phrase_subjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sujet au debut\n",
    "sujets = [\n",
    "    \"I like\",\n",
    "    \"I love\",\n",
    "    \"I prefer\",\n",
    "    \"I hate\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et à la fin (juste avant : is/are)\n",
    "sujets = [\n",
    "    \"is super\",\n",
    "    \"Amazing\",\n",
    "    \"Incredible\",\n",
    "    \"Fantastic\",\n",
    "    \"Awesome\",\n",
    "    \"Impressive\",\n",
    "    \"Terrific\",\n",
    "    \"Wonderful\",\n",
    "    \"Fabulous\",\n",
    "    \"Outstanding\",\n",
    "    \"Extraordinary\",\n",
    "    \"Excellent\",\n",
    "    \"Marvelous\",\n",
    "    \"Stunning\",\n",
    "    \"Brilliant\",\n",
    "    \"Great\",\n",
    "    \"Phenomenal\",\n",
    "    \"Astounding\",\n",
    "    \"Magnificent\",\n",
    "    \"Remarkable\",\n",
    "    \"Splendid\",\n",
    "    \"Breathtaking\",\n",
    "    \"Glorious\",\n",
    "    \"Spectacular\",\n",
    "    \"Enthralling\",\n",
    "    \"Thrilling\",\n",
    "    \"Captivating\",\n",
    "    \"Mesmerizing\",\n",
    "] # manque des négatifs.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
